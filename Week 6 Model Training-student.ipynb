{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nULkunmntyNF"
   },
   "source": [
    "# Week 6: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Module\n",
    "\n",
    "With a basic understanding of logistic regression and its role in predicting categorical outcomes, we can now focus on how to train a logistic regression model effectively.\n",
    "\n",
    "Training is a critical phase where the model learns the relationship between input features and the target variable. This step is especially important in applications such as predicting genetic traits, assessing the likelihood of medical conditions, or classifying species in ecological studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "1. Define the role of the loss function in evaluating model performance during training.\n",
    "2. Describe how gradient descent works and explain its role in optimizing model parameters.\n",
    "3. Explain the impact of key hyperparameters, including learning rate and number of epochs.\n",
    "4. Implement gradient descent using SGDClassifier to train a logistic regression model in Python.\n",
    "5. Use a validation set to select hyperparameter values and avoid overfitting.\n",
    "6. Assess model performance on training, validation, and test sets to support model selection and evaluation.\n",
    "\n",
    "By focusing on these areas, you will build a solid understanding of how to train a logistic regression model and apply it to biological data using Python. Below is last week’s preprocessing code, which brings us to the point where training begins.\n",
    "\n",
    "**Run the code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZnsa9s0tyNH",
    "outputId": "9c402289-c698-48d3-f905-79aead562226"
   },
   "outputs": [],
   "source": [
    "# Data science\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('bc_data.csv', index_col=0)\n",
    "\n",
    "print(f\"Shape of original dataset: {df.shape}\")\n",
    "\n",
    "# Data cleaning\n",
    "# Encode target feature to binary class and split target/predictor vars\n",
    "y = df[\"diagnosis\"].map({\"B\" : 0, \"M\" : 1})\n",
    "x = df.drop(\"diagnosis\", axis = 1)\n",
    "\n",
    "# Drop all \"worst\" columns\n",
    "cols = ['radius_worst',\n",
    "        'texture_worst',\n",
    "        'perimeter_worst',\n",
    "        'area_worst',\n",
    "        'smoothness_worst',\n",
    "        'compactness_worst',\n",
    "        'concavity_worst',\n",
    "        'concave points_worst',\n",
    "        'symmetry_worst',\n",
    "        'fractal_dimension_worst']\n",
    "x = x.drop(cols, axis=1)\n",
    "\n",
    "# Drop perimeter and area (keep radius)\n",
    "cols = ['perimeter_mean',\n",
    "        'perimeter_se',\n",
    "        'area_mean',\n",
    "        'area_se']\n",
    "x = x.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJO8e0TQtyNI"
   },
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before discussing how to train the model, we need to define what we are optimizing. This is where the **loss function** comes in. \n",
    "\n",
    "The <span style=\"background-color: #AFEEEE\">**loss function**</span> (also called the cost or objective function) measures how far the model’s predictions are from the true values. It assigns a numerical value to the model’s errors—larger values mean worse performance, while smaller values mean better predictions. During training, algorithms like gradient descent use this function to guide updates to the model’s parameters, gradually reducing the loss and improving accuracy. You can think of the loss function as a landscape, and training as a process of descending into the lowest valley where the model performs best.\n",
    "\n",
    "<img src=\"loss_func.jpeg\" alt=\"Gradient descent steps towards loss function minimum\" style=\"width: 600px;\" class=\"center\"/>\n",
    "\n",
    "<a href=\"https://blog.gopenai.com/understanding-of-gradient-descent-intuition-and-implementation-b1f98b3645ea\">Source</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKmN7ZcgtyNI"
   },
   "source": [
    "### Understanding Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first learned logistic regression in statistics, you may have seen formulas that give an exact solution. In many real‑world problems, though—especially in machine learning—finding such exact solutions is either too slow for large datasets or not possible at all because the models are more complex.\n",
    "\n",
    "This is where **gradient descent** comes in. Instead of solving equations directly, <span style=\"background-color: #AFEEEE\">**gradient descent**</span> trains a model by gradually improving it step by step. This approach works well even for very large or high‑dimensional datasets, like those with thousands of genetic markers or detailed medical images.\n",
    "\n",
    "Gradient descent works by repeatedly adjusting the model’s parameters to reduce the **loss function**—a measure of how far the model’s predictions are from the correct answers. Each step has two important parts:\n",
    "\n",
    "- <span style=\"background-color: #AFEEEE\">**Direction:**</span> The gradient tells us which way the loss increases fastest. To minimize loss, we move in the opposite direction.\n",
    "\n",
    "- <span style=\"background-color: #AFEEEE\">**Step size:**</span> Each step’s size matters. Too large, and we overshoot; too small, and learning becomes very slow. A well‑chosen step size helps the model reach good performance efficiently.\n",
    "\n",
    "By iterating through these steps, the model gradually “learns” from the data and finds parameter values that work well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqV2opRdtyNJ"
   },
   "source": [
    "### Working with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make gradient descent work well, we need to decide how big each step should be and how many steps to take. These decisions are controlled by <span style=\"background-color: #AFEEEE\">**hyperparameters**</span>. Unlike the model’s weights (which are learned from the data), hyperparameters are settings we choose before training begins. Every machine learning model has them, and two of the most important are the **learning rate** and the **number of epochs**.\n",
    "\n",
    "Gradient descent updates the model by repeatedly moving in the direction that reduces the loss. The size of each move is set by the **learning rate**, and the number of moves depends on how many **epochs** we run. The process stops when further steps no longer meaningfully reduce the loss. This state is called convergence—when further steps no longer significantly reduce the loss.\n",
    "\n",
    "- <span style=\"background-color: #AFEEEE\">**Learning Rate**</span>:\n",
    "The learning rate controls the size of each step. A small learning rate means tiny, careful steps (slower progress but more stable), while a large learning rate means bigger steps (faster progress but risk of overshooting). Choosing a good learning rate is key to efficient training.\n",
    "\n",
    "- <span style=\"background-color: #AFEEEE\">**Epochs**</span>:\n",
    "An epoch is one complete pass through the training data. The number of epochs controls how many times the model updates its weights. Too few epochs may stop training before the model has learned enough; too many can waste time or even lead to overfitting. The goal is to choose a number that allows the model to converge effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nngDGF9EtyNJ"
   },
   "source": [
    "In practice, when using a tool like `SGDClassifier()`, you will see parameters such as `alpha` and `max_iter`. These are the hyperparameters you set before training:\n",
    "\n",
    "- `alpha` controls the learning rate. For example, in Week 5 we used it while analyzing the breast cancer dataset.\n",
    "- `max_iter` sets the number of epochs, or how many times the model goes through the dataset.\n",
    "\n",
    "In this case, we are explicitly using a learning rate (`alpha`) of 0.00001 and 5 epochs (`max_iter=5`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gyn_E5FDtyNJ"
   },
   "source": [
    "Here are two additional functions to train and evaluate our model; we will use them frequently from now on:\n",
    "| Function | Input parameters | Output | Syntax |\n",
    "| --- | --- | --- | --- |\n",
    "| .fit() | Numpy array(s) | returns a History object containing training and validation metrics | model.fit(x_train, y_train) |\n",
    "| .score() | Numpy array(s) | returns a performance metric that is specific to the type of model | model.score(x_test, y_test) |\n",
    "\n",
    "Now, we're ready to train our model with gradient descent and evaluate how well it works. \n",
    "\n",
    "The first code cell below splits our data set into a training set (85% of the data) and a test set (15% of the data). \n",
    "\n",
    "The second code cell below trains a logistic regression model using stochastic gradient descent. It initializes the model with a learning rate 0.00001 and limits training to 5 epochs. The model is first trained on the training set, and then its accuracy is evaluated on the test set. Finally, the test accuracy is printed as a percentage.\n",
    "\n",
    "**Run the two code cells below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECZDPdR2tyNJ"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into a training and a test set\n",
    "test_ratio = 0.15\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_ratio, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMmbzy2dtyNJ",
    "outputId": "fb990da9-204f-4dbf-c535-dfbec1dc216f"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = SGDClassifier(loss='log_loss', alpha=1e-5, max_iter=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "test_predictions = model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxYbMflhtyNK"
   },
   "source": [
    "It seems our current model's performance is not as high as we hoped, returning a poor accuracy. This could be a sign that our model's hyperparameters need adjusting. For our case, it seems like the model may benefit from additional training time or a different learning rate. You might have also received a warning from `sklearn` stating so.\n",
    "\n",
    "Before we move on, run the previous cell a few more times. You may see that the accuracy produced seems random. This is because we may start at various random locations on this gradient, and the weights are initialized randomly.\n",
    "\n",
    "---\n",
    "**Q*1. In the code snippet below, experiment with different values for `alpha` and `max_iter` until you get an accuracy above 80% on the test set.**\n",
    "\n",
    "> HINT: Refer to the code from the code cell above.\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "# Fit the model on the training data\n",
    "\n",
    "# Evaluate the model on the testing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emptmvOTtyNK"
   },
   "source": [
    "### Validation Set\n",
    "\n",
    "It’s tempting to celebrate high accuracy on the test set, but this can be misleading if it results from <span style=\"background-color: #AFEEEE\">**overfitting**</span> (we’ll explore overfitting and underfitting in Week 7). In this case, overfitting may have happened because we have used the test set to choose hyperparameter values, allowing information from the test set to influence our model performance. As a result, the test set no longer provides an objective measure of our model performance.\n",
    "\n",
    "To prevent this, we need a different strategy. Instead of relying on the test set for choosing hyperparameter values, we will create a validation set by splitting off a portion of the current training set. The validation set allows us to evaluate and adjust hyperparameter values while keeping the test set completely untouched.\n",
    "\n",
    "To summarize, we will split our data into three distinct sets. It is important these three sets are kept separate and used for their specific purposes only.\n",
    "- The <span style=\"background-color: #AFEEEE\">**training set**</span> is used to learn the model’s parameters—that is, the internal values that minimize the loss function.\n",
    "- The <span style=\"background-color: #AFEEEE\">**validation set**</span> is used to choose hyperparameters and guide model selection.\n",
    "- The <span style=\"background-color: #AFEEEE\">**test set**</span> remains untouched throughout development and is used only once, at the end, to assess how well the final model generalizes to new, unseen data.\n",
    "\n",
    "In practice, the training set is usually the largest portion, while the validation and test sets are smaller—often around 10–20% of the data each—depending on the size of the overall dataset.\n",
    "\n",
    "<img src=\"data_split.png\" alt=\"Orginial data vs data when it is split into train, validation, and test sets\" style=\"width: 600px;\" class=\"center\"/>\n",
    "\n",
    "Now, let's try to split our current training data (`x_train` and `y_train`) further into a training set (`x_train` and `y_train`) and a validation set (`x_val` and `y_val`).\n",
    "\n",
    "**Run the code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCsvs2Q_tyNK"
   },
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "# train (70%), val (15%), test (15%)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "\n",
    "# Splitting the training from the validation set\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_ratio/(train_ratio + val_ratio), random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEmlUmNvtyNK"
   },
   "source": [
    "---\n",
    "**Q*2. Let's experiment with different numbers of epochs/iterations. Specifically, we will test what happens if we were to increase the number from 5 epochs to 10, 50, and 100. Below, there are three code cells for you to fill out. Copy the code above and change the `max_iter` parameter. Remember to set `random_state` to 1**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GIJoehPMtyNL"
   },
   "outputs": [],
   "source": [
    "# Max iterations of 10\n",
    "model = SGDClassifier(loss='log_loss', alpha=1e-5, max_iter=..., random_state=...)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_score = model.score(x_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDQvQMPItyNL"
   },
   "outputs": [],
   "source": [
    "# Max iterations of 50\n",
    "\n",
    "# Fit the model on the training data\n",
    "\n",
    "# Evaluate the model on the validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhLIvFKttyNL"
   },
   "outputs": [],
   "source": [
    "# Max iterations of 100\n",
    "\n",
    "# Fit the model on the training data\n",
    "\n",
    "# Evaluate the model on the validation data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvUddNK-tyNL"
   },
   "source": [
    "---\n",
    "**Q*3. After making these changes, observe how the test accuracy has shifted. Did it improve? If so, explain why conceptually you think that increasing the number of epochs helped in this case. What oddity do you observe when you compare 50 to 100 epochs? Why may that be?**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Impact of Varying the Learning Rate\n",
    "\n",
    "Let’s explore how the learning rate influences model training. This hyperparameter controls the step size taken during gradient descent, and its value has a major impact on convergence. If the learning rate is too low, training may be painfully slow or get stuck in local minima. If it’s too high, the model might overshoot the minimum or fail to converge entirely.\n",
    "\n",
    "A common mistake is underestimating the scale of this parameter. For example, a learning rate of 0.1 is not just slightly larger than 0.01—it’s ten times larger, and that difference can dramatically affect training dynamics.\n",
    "\n",
    "Tuning the learning rate is a common challenge for beginners. A typical starting point is somewhere between 0.001 and 0.1, depending on the model and dataset. Begin with a moderate value like 0.01, observe training behavior, and adjust gradually. Visualizing the loss over time can help guide this process and reveal whether the learning rate needs to be increased or decreased.\n",
    "\n",
    "The figure below illustrates what happens when the learning rate is set too high: the model fails to settle into a minimum, even after many epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eB2udVamtyNL"
   },
   "source": [
    "<img src=\"lr_effect.png\" alt=\"Choice of learning rate and impact on gradient descent\" style=\"width: 600px;\" class=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Q*4. Below in the two cells, examine what happens when you set the `alpha` value to 1 and 1e-1, respectively. You may keep the `max_iterations` as 100.**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwgAvLbctyNL"
   },
   "outputs": [],
   "source": [
    "# Alpha value of 1\n",
    "model = SGDClassifier(loss='log_loss', alpha=..., max_iter=..., random_state=1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_score = model.score(x_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVYN7FxStyNL"
   },
   "outputs": [],
   "source": [
    "# Alpha value of 0.1\n",
    "\n",
    "# Fit the model on the training data\n",
    "\n",
    "# Evaluate the model on the validation data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXW4XoS6tyNM"
   },
   "source": [
    "---\n",
    "**Q*5. What are the results that you see when changing the alpha value? If the learning rate is too small, what can you do to make sure that the model converges (besides changing the alpha value)?**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KakTuo5tyNM"
   },
   "source": [
    "### Final Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we’ve completed training and hyperparameter tuning, it’s time to evaluate our model on the test set. Use the code below to make predictions on the test data (not the validation set) and assess its performance.\n",
    "\n",
    "---\n",
    "**Q*6. As we have altered and explored different hyperparameter values for our model, retrain the model below with what you believe are the best hyperparameter values and evaluate your model on the test dataset.**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8blr1HztyNM"
   },
   "outputs": [],
   "source": [
    "# Load the model with the best hyperparameters from our experiments\n",
    "model = SGDClassifier(loss='log_loss', alpha=..., max_iter=..., random_state=...)\n",
    "\n",
    "# Fit the model on the training data\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_predictions = ...\n",
    "val_accuracy = ...\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "test_predictions = ...\n",
    "test_accuracy = ...\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3x_0ZGityNM"
   },
   "source": [
    "## **Graded Exercises: (7 marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GQ*1: Read in the heart failures dataset (`hf_data_tut.csv`) (1 mark) and split the predictor variables (features) from the labels (response variable) (1 mark).**\n",
    "\n",
    "> HINT: Look at your work from Week 3.\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18aCqYmRtyNM"
   },
   "source": [
    "**GQ*2: Train an `SGDClassifier()` model on *all* the data (1 mark). What is the accuracy (1 mark)?**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXdx7fw7tyNM"
   },
   "outputs": [],
   "source": [
    "...\n",
    "accuracy = ...\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GQ*3: Split the dataset into a train and test set and retrain your model (1 mark). What is the train and test accuracy (2 marks)?**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "\n",
    "# Retrain model\n",
    "\n",
    "# Training accuracy\n",
    "train_predictions = ...\n",
    "train_accuracy = ...\n",
    "print(f\"Train accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Testing accuracy\n",
    "test_predictions = ...\n",
    "test_accuracy = ...\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwvXcu3ktyNN"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this module, we explored the concept of training in the context of logistic regression.\n",
    "\n",
    "We introduced <span style=\"background-color: #AFEEEE\">**gradient descent**</span>, a widely used optimization method that adjusts model weights to minimize the loss function—a measure of how well the model’s predictions match the actual labels.\n",
    "\n",
    "We also discussed the role of <span style=\"background-color: #AFEEEE\">**hyperparameters**</span>—user-defined settings like the learning rate and number of epochs—which influence the training process but are not learned from the data.\n",
    "\n",
    "To tune these hyperparameters effectively, we introduced the <span style=\"background-color: #AFEEEE\">**validation set**</span>, a portion of the data set aside from training to guide model selection while keeping the test set untouched.\n",
    "\n",
    "Finally, we examined the challenges of hyperparameter tuning, focusing on how poor choices—especially in learning rate or training duration—can significantly affect model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
